{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b69ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Afnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy is  0.9122828282828283\n",
      "[[11497   884]\n",
      " [ 1287 11082]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "train_set = r'C:\\Users\\Afnan\\PycharmProjects\\part 1\\Dataset\\train'\n",
    "movie_train = load_files(train_set, shuffle=True)\n",
    "\n",
    "\n",
    "test_set = r'C:\\Users\\Afnan\\PycharmProjects\\part 1\\Dataset\\test'\n",
    "movie_test = load_files(test_set, shuffle=True)\n",
    "with open(r'C:\\Users\\Afnan\\PycharmProjects\\part 1\\Dataset\\stop_words.txt') as file:\n",
    "    stop_words_list = file.readlines()\n",
    "    stop_words_list = [line.rstrip() for line in stop_words_list]\n",
    "\n",
    "\n",
    "\n",
    "movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize,stop_words=stop_words_list)\n",
    "train_movie_counts = movie_vec.fit_transform(movie_train.data)\n",
    "\n",
    "movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize,stop_words=stop_words_list)\n",
    "test_movie_counts = movie_vec.fit_transform(movie_test.data)\n",
    "\n",
    "\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "train_movie_tfidf = tfidf_transformer.fit_transform(train_movie_counts)\n",
    "test_movie_tfidf = tfidf_transformer.fit_transform(test_movie_counts)\n",
    "\n",
    "\n",
    "\n",
    "docs_train, _, y_train, _ = train_test_split(train_movie_tfidf, movie_train.target, test_size = 0.01, random_state = 12)\n",
    "docs_test, _, y_test, _= train_test_split(train_movie_tfidf, movie_train.target, test_size = 0.01, random_state = 12)\n",
    "\n",
    "###################################################################################################\n",
    "clf = MultinomialNB().fit(docs_train, y_train)\n",
    "y_pred = clf.predict(docs_test)\n",
    "print(\"Testing Accuracy is \",sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfbb1b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done frequency counting\n",
      "done positive probability dictionary\n",
      "negative dictionary\n",
      "\n",
      "Results\n",
      "=======\n",
      "                    Gold positive  Gold negative\n",
      "Predicted positive           9802           1220\n",
      "Predicted negative           2698          11280\n",
      "accuracy=0.84328\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "'''According to the textbook,In most text classifica-\n",
    "tion applications, however, using a stop word list doesnâ€™t improve performance, and\n",
    "so it is more common to make use of the entire vocabulary and not use a stop word\n",
    "list.'''\n",
    "pos_path = 'D:dataset\\\\train\\\\pos\\\\'\n",
    "neg_path = 'D:dataset\\\\train\\\\neg\\\\'\n",
    "\n",
    "test_neg = 'D:dataset\\\\test\\\\neg\\\\'\n",
    "test_pos = 'D:dataset\\\\test\\\\pos\\\\'\n",
    "f = open(r'C:\\Users\\Afnan\\PycharmProjects\\part 1\\Dataset\\stop_words.txt', \"r\", encoding=\"utf8\")\n",
    "stopWords = f.read().split()\n",
    "f.close()\n",
    "\n",
    "pos_listing = os.listdir(pos_path)\n",
    "neg_listing = os.listdir(neg_path)\n",
    "\n",
    "test_listing_n = os.listdir(test_neg)\n",
    "test_listing_p = os.listdir(test_pos)\n",
    "\n",
    "vocab = set()\n",
    "\n",
    "pos_totalWords = []\n",
    "neg_totalWords = []\n",
    "\n",
    "# positive files\n",
    "for file in pos_listing:\n",
    "\n",
    "    f = open(pos_path + file, \"r\", encoding=\"utf8\")\n",
    "\n",
    "    allWords = f.read().split()\n",
    "\n",
    "    for word in allWords:\n",
    "        vocab.add(word.lower())\n",
    "        pos_totalWords.append(word.lower())\n",
    "\n",
    "    f.close()\n",
    "\n",
    "# negative files\n",
    "for file in neg_listing:\n",
    "\n",
    "    f = open(neg_path + file, \"r\", encoding=\"utf8\")\n",
    "\n",
    "    allWords = f.read().split()\n",
    "\n",
    "    for word in allWords:\n",
    "        vocab.add(word.lower())\n",
    "        neg_totalWords.append(word.lower())\n",
    "\n",
    "    f.close()\n",
    "\n",
    "for word in stopWords:\n",
    "    try:\n",
    "        pos_totalWords.remove(word)\n",
    "        neg_totalWords.remove(word)\n",
    "        vocab.remove(word)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "pos_dict = dict.fromkeys(vocab, 0)\n",
    "neg_dict = dict.fromkeys(vocab, 0)\n",
    "\n",
    "for p in pos_totalWords:\n",
    "    key = p\n",
    "    if key in vocab:\n",
    "        pos_dict[p] += 1\n",
    "\n",
    "for p in neg_totalWords:\n",
    "    key = p\n",
    "    if key in vocab:\n",
    "        neg_dict[p] += 1\n",
    "\n",
    "print(\"done frequency counting\")\n",
    "\n",
    "pos_prob = dict.fromkeys(vocab, 0)\n",
    "neg_prob = dict.fromkeys(vocab, 0)\n",
    "\n",
    "for word in pos_dict:\n",
    "    pos_prob[word] = (pos_dict[word] + 1) / (len(pos_totalWords) + len(vocab))\n",
    "\n",
    "print(\"done positive probability dictionary\")\n",
    "\n",
    "for word in neg_dict:\n",
    "    neg_prob[word] = (neg_dict[word] + 1) / (len(neg_totalWords) + len(vocab))\n",
    "\n",
    "print(\"negative dictionary\")\n",
    "\n",
    "pos_probability = 0\n",
    "neg_probability = 0\n",
    "pos_review_pos_test = 0\n",
    "neg_review_pos_test = 0\n",
    "pos_review_neg_test = 0\n",
    "neg_review_neg_test = 0\n",
    "\n",
    "for file in test_listing_p:\n",
    "    f = open(test_pos + file, \"r\", encoding=\"utf8\")\n",
    "\n",
    "    allWords = f.read().split()\n",
    "\n",
    "    for word in allWords:\n",
    "        try:\n",
    "            pos_probability += math.log(pos_prob[word])  # prior probability is constant so it doesnt matter anyway\n",
    "            neg_probability += math.log(neg_prob[word])\n",
    "        except KeyError:\n",
    "            pos_probability += 0\n",
    "            neg_probability += 0\n",
    "\n",
    "    if pos_probability > neg_probability:\n",
    "        pos_review_pos_test += 1\n",
    "    else:\n",
    "        neg_review_pos_test += 1\n",
    "\n",
    "    pos_probability = 0\n",
    "    neg_probability = 0\n",
    "\n",
    "for file in test_listing_n:\n",
    "    f = open(test_neg + file, \"r\", encoding=\"utf8\")\n",
    "\n",
    "    allWords = f.read().split()\n",
    "\n",
    "    for word in allWords:\n",
    "        try:\n",
    "            pos_probability += math.log(pos_prob[word])\n",
    "            neg_probability += math.log(neg_prob[word])\n",
    "        except KeyError:\n",
    "            pos_probability += 0\n",
    "            neg_probability += 0\n",
    "\n",
    "    if pos_probability > neg_probability:\n",
    "        pos_review_neg_test += 1\n",
    "    else:\n",
    "        neg_review_neg_test += 1\n",
    "\n",
    "    pos_probability = 0\n",
    "    neg_probability = 0\n",
    "\n",
    "print(\"\")\n",
    "print(\"Results\")\n",
    "print(\"=======\")\n",
    "cfm = pd.DataFrame([[pos_review_pos_test, pos_review_neg_test], [neg_review_pos_test, neg_review_neg_test]],\n",
    "                   columns=('Gold positive', 'Gold negative'), index=('Predicted positive', 'Predicted negative'))\n",
    "print(cfm)\n",
    "ac = (pos_review_pos_test + neg_review_neg_test) / (\n",
    "            pos_review_pos_test + pos_review_neg_test + neg_review_neg_test + neg_review_pos_test)\n",
    "print(\"accuracy={}\".format(ac))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02341b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
